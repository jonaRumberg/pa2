%---------------------
% Bücher
%---------------------
@article{test,
  author     = {Grande, Marcus},
  sortname   = {Grande, Marcus},
  title      = {100 Minuten für Anforderungsmanagement: Kompaktes Wissen nicht nur für Projektleiter und Entwickler},
  shorttitle = {100 Minuten für Anforderungsmanagement},
  year       = 2011,
  publisher  = {Vieweg + Teubner Verlag},
  location   = {Wiesbaden},
  edition    = {1}
}

@article{Freund2014,
  author    = {Freund, Jakob and Rücker, Bernd},
  title     = {Praxishandbuch BPMN 2.0},
  address   = {München; Wien},
  publisher = {Hanser},
  year      = {2014},
  edition   = {4., aktualisierte Aufl.},
  isbn      = {978-3-446-44255-9}
}

%---------------------
% Sammelwerke
%---------------------
@article{Meuser2009,
  author    = {Meuser, Michael
               and Nagel, Ulrike},
  editor    = {Pickel, Susanne
               and Pickel, Gert
               and Lauth, Hans-Joachim
               and Jahn, Detlef},
  title     = {Das Experteninterview --- konzeptionelle Grundlagen und methodische Anlage},
  booktitle = {Methoden der vergleichenden Politik- und Sozialwissenschaft: Neue Entwicklungen und Anwendungen},
  year      = {2009},
  publisher = {VS Verlag f{\"u}r Sozialwissenschaften},
  address   = {Wiesbaden},
  isbn      = {978-3-531-91826-6}
}

%---------------------
% Zeitschriftenartikel
%---------------------
@article{WIWO2018,
  author  = {{o.V.}},
  title   = {Der unkontrollierte Boom},
  journal = {Wirtschaftswoche},
  year    = {2018},
  volume  = {(2018), Heft 15 vom 06.04.2018}
}

%---------------------
% Internetquellen
%---------------------
@online{DHBW,
  author  = {{DHBW Lörrach}},
  title   = {DHBW Startseite},
  year    = 2018,
  url     = {http://www.dhbw-loerrach.de/},
  urldate = {2018-03-30}
}

@online{OMG2018,
  author  = {{Object Management Group}},
  title   = {OMG Startseite},
  year    = 2000,
  url     = {http://www.dhbw-loerrach.de/},
  urldate = {2018-03-30}
}

@online{schlechteQuelle,
  author  = {{o.V.}},
  title   = {Eine Quelle ohne Verfasser und ohne Jahr},
  year    = 2000,
  url     = {https://www.google.de//},
  urldate = {2018-04-10}
}

@online{schlechteQuelle2,
  author  = {{o.V.}},
  year    = 2000,
  url     = {https://www.amazon.de//},
  urldate = {2018-04-12}
}

 @online{davies_2015,
  title   = {English-Corpora: Wikipedia},
  url     = {https://www.english-corpora.org/wiki},
  journal = {www.english-corpora.org},
  author  = {Davies, Mark},
  year    = {2015}
}

 @book{jurafsky_martin_2020,
  title  = {Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition},
  url    = {https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf},
  note   = {draft},
  author = {Jurafsky, Daniel and Martin, James},
  year   = {2020},
  annote = {draft}
}

@article{RUMELHART19731,
  title    = {A model for analogical reasoning},
  journal  = {Cognitive Psychology},
  volume   = {5},
  number   = {1},
  pages    = {1-28},
  year     = {1973},
  issn     = {0010-0285},
  doi      = {https://doi.org/10.1016/0010-0285(73)90023-6},
  url      = {https://www.sciencedirect.com/science/article/pii/0010028573900236},
  author   = {David E Rumelhart and Adele A Abrahamson},
  abstract = {A theory of analogical reasoning is proposed in which the elements of a set of concepts, e.g., animals, are represented as points in a multidimensional Euclidean space. Four elements A,B,C,D, are in an analogical relationship A:B::C:D if the vector distance from A to B is the same as that from C to D. Given three elements A,B,C, an ideal solution point I for A:B::C:? exists. In a problem A:B::C:D1, …, Di, …, Dn, the probability of choosing Di as the best solution is a monotonic decreasing function of the absolute distance of Di from I. A stronger decision rule incorporating a negative exponential function in Luce's choice rule is also proposed. Both the strong and weak versions of the theory were supported in two experiments where Ss rank-ordered the alternatives in problems A:B::C:D1,D2, D3D4. In a third experiment the theory was applied and further tested in teaching new concepts by analogy.}
}

 @article{mikolov_chen_corrado_dean_2013,
  title  = {Efficient Estimation of Word Representations in Vector Space},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year   = {2013},
  url    = {https://arxiv.org/pdf/1301.3781}
}

 @book{bishop_2006,
  title     = {Pattern Recoginition and Machine Learning},
  url       = {https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf},
  publisher = {Springer},
  author    = {Bishop, Christopher},
  editor    = {Kleinberg and Schölkopf and Jordan},
  year      = {2006}
}

@article{DBLP:journals/corr/abs-2005-11401,
  author     = {Patrick S. H. Lewis and
                Ethan Perez and
                Aleksandra Piktus and
                Fabio Petroni and
                Vladimir Karpukhin and
                Naman Goyal and
                Heinrich K{\"{u}}ttler and
                Mike Lewis and
                Wen{-}tau Yih and
                Tim Rockt{\"{a}}schel and
                Sebastian Riedel and
                Douwe Kiela},
  title      = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  journal    = {CoRR},
  volume     = {abs/2005.11401},
  year       = {2020},
  url        = {https://arxiv.org/abs/2005.11401},
  eprinttype = {arXiv},
  eprint     = {2005.11401},
  timestamp  = {Fri, 29 May 2020 09:57:22 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2005-11401.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{semantic_search,
author = {Kenter, Tom and de Rijke, Maarten},
title = {Short Text Similarity with Word Embeddings},
year = {2015},
isbn = {9781450337946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2806416.2806475},
doi = {10.1145/2806416.2806475},
abstract = {Determining semantic similarity between texts is important in many tasks in information retrieval such as search, query suggestion, automatic summarization and image finding. Many approaches have been suggested, based on lexical matching, handcrafted patterns, syntactic parse trees, external sources of structured semantic knowledge and distributional semantics. However, lexical features, like string matching, do not capture semantic similarity beyond a trivial level. Furthermore, handcrafted patterns and external sources of structured semantic knowledge cannot be assumed to be available in all circumstances and for all domains. Lastly, approaches depending on parse trees are restricted to syntactically well-formed texts, typically of one sentence in length.We investigate whether determining short text similarity is possible using only semantic features---where by semantic we mean, pertaining to a representation of meaning---rather than relying on similarity in lexical or syntactic representations. We use word embeddings, vector representations of terms, computed from unlabelled data, that represent terms in a semantic space in which proximity of vectors can be interpreted as semantic similarity.We propose to go from word-level to text-level semantics by combining insights from methods based on external sources of semantic knowledge with word embeddings. A novel feature of our approach is that an arbitrary number of word embedding sets can be incorporated. We derive multiple types of meta-features from the comparison of the word vectors for short text pairs, and from the vector means of their respective word embeddings. The features representing labelled short text pairs are used to train a supervised learning algorithm. We use the trained model at testing time to predict the semantic similarity of new, unlabelled pairs of short texts We show on a publicly available evaluation set commonly used for the task of semantic similarity that our method outperforms baseline methods that work under the same conditions.},
booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
pages = {1411–1420},
numpages = {10},
keywords = {short text similarity, word embeddings},
location = {Melbourne, Australia},
series = {CIKM '15}
}

@inproceedings{Khandelwal2020Generalization,
  title     = {Generalization through Memorization: Nearest Neighbor Language Models},
  author    = {Urvashi Khandelwal and Omer Levy and Dan Jurafsky and Luke Zettlemoyer and Mike Lewis},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=HklBjCEKvH}
}

%---------------------
% Firmeninterne Dokumente
%---------------------
@unpublished{Firma2018,
  author = {Julia Musterfrau},
  title  = {Die Geschichte der Musterfrau AG},
  year   = {2018}
}

%---------------------
% Interviewprotokolle
%---------------------
@interview{Experte2018,
  author = {Hans Expertmann},
  title  = {Aktueller Fertigungsprozess},
  year   = {2018}
}
